{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "biblical-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "emotional-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_dir = pathlib.Path('./code')\n",
    "embedding_dir = pathlib.Path('./embeddings')\n",
    "negative_samples_dir = pathlib.Path('./embeddings/negative_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monthly-telling",
   "metadata": {},
   "outputs": [],
   "source": [
    "antipatterns = list(embedding_dir.glob('*'))\n",
    "antipatterns_dict = {}\n",
    "for antipattern in antipatterns:\n",
    "    if antipattern != negative_samples_dir:\n",
    "        antipatterns_dict[antipattern.name] = list(antipattern.glob('*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65737100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['parallel_inheritance_hierarchies', 'god_classes', 'data_class', 'feature_envy'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antipatterns_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mobile-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = defaultdict(lambda : [False, False, False, False, ''])\n",
    "name2label = {name:i for name, i in zip(antipatterns_dict, range(len(antipatterns_dict)))}\n",
    "label2name = {value:key for key, value in name2label.items()}\n",
    "for name, paths in antipatterns_dict.items():\n",
    "    for path in paths:\n",
    "        labels[os.path.basename(path)][name2label[name]] = True\n",
    "        labels[os.path.basename(path)][-1] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "universal-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(filename):\n",
    "    return np.array([float(x) for x in filename.open().read().split()])\n",
    "\n",
    "for name, values in labels.items():\n",
    "    labels[name].append(get_embedding(values[-1]).reshape(384, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c395bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_samples = random.sample(list(negative_samples_dir.glob('*')), 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae743e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for negative_sample in negative_samples:\n",
    "    embedding = get_embedding(negative_sample).reshape(384, -1)\n",
    "    labels[negative_sample.name] = [False, False, False, False, negative_sample, embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "growing-caution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parallel_inheritance_hierarchies': 0,\n",
       " 'god_classes': 1,\n",
       " 'data_class': 2,\n",
       " 'feature_envy': 3}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "precious-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_labels(name):\n",
    "    return (\n",
    "        [np.mean(values[-1], axis=1) for values in labels.values()], \n",
    "        [values[name2label[name]] for values in labels.values()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "graduate-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def fit(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "    svm = SVC()\n",
    "    svm.fit(X_train, y_train)\n",
    "    preds = svm.predict(X_test)\n",
    "    print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-hospital",
   "metadata": {},
   "source": [
    "## Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_train_labels('data_class')\n",
    "fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-position",
   "metadata": {},
   "source": [
    "## God Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_train_labels('god_classes')\n",
    "fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-laptop",
   "metadata": {},
   "source": [
    "## Feature envy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_train_labels('feature_envy')\n",
    "fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-malawi",
   "metadata": {},
   "source": [
    "## Parallel inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_train_labels('parallel_inheritance_hierarchies')\n",
    "fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-projection",
   "metadata": {},
   "source": [
    "## Skmultilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "simplified-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    np.array([np.mean(values[-1], axis=1) for values in labels.values()]), \n",
    "    np.array([values[:4] for values in labels.values()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "affecting-affair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(verbose=1), require_dense=[False, True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import BinaryRelevance from skmultilearn\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "# Import SVC classifier from sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Setup the classifier\n",
    "classifier = BinaryRelevance(classifier=SVC(verbose=1), require_dense=[False,True])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Train\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3902b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:10].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65a83d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"bin_rel_svc_3000_neg_samples.pckl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "589432d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.17      0.29       925\n",
      "           1       0.74      0.65      0.70       680\n",
      "           2       0.68      0.67      0.67      1268\n",
      "           3       0.86      1.00      0.92      4900\n",
      "\n",
      "   micro avg       0.82      0.81      0.82      7773\n",
      "   macro avg       0.81      0.62      0.65      7773\n",
      "weighted avg       0.83      0.81      0.79      7773\n",
      " samples avg       0.82      0.77      0.77      7773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/species_decipit/PycharmProjects/thesis/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/species_decipit/PycharmProjects/thesis/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8617f3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6289393425957303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for y, y_hat in zip(y_test, np.asarray(y_pred.todense())):\n",
    "    if (y == y_hat).all():\n",
    "        correct += 1\n",
    "    total += 1\n",
    "\n",
    "correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-stranger",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import ClassifierChain, LabelPowerset\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.cluster.networkx import NetworkXLabelGraphClusterer\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "from skmultilearn.ensemble import LabelSpacePartitioningClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "parameters = {\n",
    "    'classifier': [BinaryRelevance(), ClassifierChain()],\n",
    "    'classifier__classifier': [RandomForestClassifier()],\n",
    "    'classifier__classifier__n_estimators': [10, 20, 50],\n",
    "    \n",
    "    'clusterer' : [\n",
    "        NetworkXLabelGraphClusterer(LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False), 'louvain'),\n",
    "        NetworkXLabelGraphClusterer(LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False), 'lpa')\n",
    "    ]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(LabelSpacePartitioningClassifier(), parameters, scoring = 'f1_macro')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parameters = {'k': range(1,6), 's': [0.0, 0.5, 0.7, 1.0]}\n",
    "score = 'f1_micro'\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring=score)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print (clf.best_params_, clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "edge_map = graph_builder.transform(y_train)\n",
    "print(\"{} labels, {} edges\".format(4, len(edge_map)))\n",
    "print(edge_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "{(label2name[key[0]],label2name[key[1]]):value for key, value in edge_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# we define a helper function for visualization purposes\n",
    "def to_membership_vector(partition):\n",
    "    return {\n",
    "        member :  partition_id\n",
    "        for partition_id, members in enumerate(partition)\n",
    "        for member in members\n",
    "    }\n",
    "clusterer = NetworkXLabelGraphClusterer(graph_builder, method='louvain')\n",
    "partition = clusterer.fit_predict(X_train,y_train)\n",
    "\n",
    "membership_vector = to_membership_vector(partition)\n",
    "\n",
    "names_dict = dict(enumerate(x for x in ['data', 'god', 'envy', 'inheritance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(\n",
    "    clusterer.graph_,\n",
    "    pos=nx.circular_layout(clusterer.graph_),\n",
    "    labels=names_dict,\n",
    "    with_labels = True,\n",
    "    width = [10*x/y_train.shape[0] for x in clusterer.weights_['weight']],\n",
    "    node_color = [membership_vector[i] for i in range(y_train.shape[1])],\n",
    "    cmap=plt.cm.Spectral,\n",
    "    node_size=100,\n",
    "    font_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-banks",
   "metadata": {},
   "source": [
    "Reference: [Scikit Multilearn doc](http://scikit.ml/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-windsor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
